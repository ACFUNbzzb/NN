import os
import numpy as np
import pandas as pd
import shap
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from matminer.featurizers.composition import ElementProperty
from matminer.featurizers.conversions import StrToComposition
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
from scipy.stats import spearmanr, pearsonr


# ========= æ¨¡å—1ï¼šå‡†å¤‡åŒ–å­¦å¼æ•°æ®å¹¶æå–ç‰¹å¾ =========
def prepare_multi_system_inputs():
    """å‡†å¤‡50ä¸ªåŒ–å­¦å¼æ ·æœ¬ï¼Œå¹¶æå–å¯¹åº”çš„ç‰¹å¾"""
    system_bases = [
        'Li26Ni27FeO54', 'Li25Ni27Fe2O54', 'Li24Ni27Fe3O54', 'Li23Ni27Fe4O54', 'Li22Ni27Fe5O53',
        'Li26Ni27O54', 'Li27Ni27O54', 'Li27Ni27O53', 'Li27Ni27O52', 'Li25Ni27CoMnO54',
        'Li26Ni27CoO54', 'Li25Ni27Co2O54', 'Li24Ni27Co3O54', 'Li23Ni27Co4O54', 'Li22Ni27Co5O53',
        'Li26Ni27MnO54', 'Li25Ni27Mn2O54', 'Li24Ni27Mn3O54', 'Li23Ni27Mn4O54', 'Li22Ni27Mn5O53',
        'Li26Ni27AlO54', 'Li25Ni27Al2O54', 'Li24Ni27Al3O54', 'Li23Ni27Al4O54', 'Li22Ni27Al5O53',
        'Li26Ni27Fe3MnO54', 'Li25Ni27Fe2Mn2O54', 'Li24Ni27FeMn3O54', 'Li23Ni27Mn4FeO54', 'Li22Ni27Mn5FeO53',
        'Li26Ni27Fe3CoO54', 'Li25Ni27Fe2Co2O54', 'Li24Ni27FeCo3O54', 'Li23Ni27Co4FeO54', 'Li22Ni27Co5FeO53',
        'Li26Ni27CoMn2O54', 'Li25Ni27CoMn3O54', 'Li24Ni27CoMn4O54', 'Li23Ni27CoMn5O54', 'Li22Ni27CoMn6O53',
        'Li26Ni27Co2AlO54', 'Li25Ni27Co2Al2O54', 'Li24Ni27Co2Al3O54', 'Li23Ni27Co2Al4O54', 'Li22Ni27Co2Al5O53',
        'Li26Ni27Mn2AlO54', 'Li25Ni27Mn2Al2O54', 'Li24Ni27Mn2Al3O54', 'Li23Ni27Mn2Al4O54', 'Li22Ni27Mn2Al5O53'
    ]

    featurizer = ElementProperty.from_preset("magpie", impute_nan=True)
    X_all, y_all = [], []
    success_list, fail_list = [], []

    for idx, formula in enumerate(system_bases):
        try:
            df = pd.DataFrame({'formula': [formula]})
            df = StrToComposition().featurize_dataframe(df, col_id='formula', ignore_errors=False)
            df = featurizer.featurize_dataframe(df, col_id='composition', ignore_errors=False)
            features = df.drop(columns=['formula', 'composition']).values[0]
            X_all.append(features)
            y_all.append(0.4 + 0.01 * idx)  # æ¨¡æ‹Ÿæ ‡ç­¾
            success_list.append(formula)
        except Exception as e:
            print(f"âŒ é”™è¯¯å¤„ç†åŒ–å­¦å¼ {formula}: {e}")
            fail_list.append(formula)

    X_merged = np.array(X_all)
    y_merged = np.array(y_all)

    # âœ… è¯´æ˜ç»Ÿè®¡è¡¨æ ¼å†…å®¹
    print(f"\nğŸ“Š å½“å‰æˆåŠŸæå–ç‰¹å¾çš„æ ·æœ¬æ•°: {X_merged.shape[0]}ï¼Œæ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾ç»´åº¦: {X_merged.shape[1]}")
    print("ğŸ“ˆ ä»¥ä¸‹ä¸ºç‰¹å¾åˆ—çš„ç»Ÿè®¡åˆ†å¸ƒï¼ˆæ³¨æ„ï¼šæ˜¯æ¯åˆ—çš„æè¿°ï¼Œä¸æ˜¯æ ·æœ¬è¡Œæ•°ï¼‰:")
    print(pd.DataFrame(X_merged).describe())

    # âœ… æ‰“å°æˆåŠŸå’Œå¤±è´¥åˆ—è¡¨
    print(f"\nâœ… æˆåŠŸæå–åŒ–å­¦å¼æ•°é‡: {len(success_list)}")
    print(f"âŒ æå–å¤±è´¥æ•°é‡: {len(fail_list)}")
    if fail_list:
        print("å¤±è´¥åŒ–å­¦å¼å¦‚ä¸‹ï¼š", fail_list)

    return X_merged, y_merged


# ========= æ¨¡å—2ï¼šæ•°æ®æ ‡å‡†åŒ– =========
def augment_with_noise(X, y, target_size=100, noise_level_X=0.01, noise_level_y=0.005):
    """æ‰©å……æ•°æ®åˆ°æŒ‡å®šæ•°é‡ï¼ˆ100ï¼‰ï¼Œå¹¶æ·»åŠ å™ªå£°"""
    X_aug, y_aug = [X.copy()], [y.copy()]
    rng = np.random.default_rng()
    while len(X_aug) * X.shape[0] < target_size:
        noise_X = rng.normal(0, noise_level_X, X.shape)
        noise_y = rng.normal(0, noise_level_y, y.shape)
        X_aug.append(X + noise_X)
        y_aug.append(y + noise_y)
    X_final = np.vstack(X_aug)[:target_size]
    y_final = np.hstack(y_aug)[:target_size]
    return X_final, y_final


# ========= æ¨¡å—3ï¼šæ•°æ®é›†å°è£… =========
class MultiSystemDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)


# ========= æ¨¡å—4ï¼šæ¨¡å‹ç»“æ„ =========
class BatteryModel(nn.Module):
    def __init__(self, input_dim, hidden_units=64):
        super(BatteryModel, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, hidden_units),
            nn.ReLU(),
            nn.Linear(hidden_units, hidden_units),
            nn.ReLU(),
            nn.Linear(hidden_units, 1)
        )

    def forward(self, x):
        return self.fc(x)


# ========= ä¸»ç¨‹åºå…¥å£ =========
if __name__ == '__main__':
    os.makedirs("training_output", exist_ok=True)
    os.makedirs("prediction_output", exist_ok=True)
    os.makedirs("saved_model", exist_ok=True)
    shap.initjs()

    # åŸå§‹æ•°æ®å‡†å¤‡
    X_raw, y_raw = prepare_multi_system_inputs()
    num_total = X_raw.shape[0]

    if num_total < 20:
        raise ValueError(f"â— åŸå§‹æ ·æœ¬æ•°ä»…æœ‰ {num_total}ï¼Œä¸è¶³ä»¥åˆ’åˆ†10ä¸ªéªŒè¯å’Œè¶³å¤Ÿè®­ç»ƒã€‚")

    # 1ï¸âƒ£ åˆ’åˆ†æ•°æ®é›†ï¼š10ä¸ªéªŒè¯ï¼Œå…¶ä½™ç”¨äºè®­ç»ƒ
    X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(
        X_raw, y_raw, test_size=10, random_state=42
    )

    # 2ï¸âƒ£ å†ä»è®­ç»ƒé›†ä¸­åˆ’åˆ† 20% ä¸ºæµ‹è¯•é›†
    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
        X_train_raw, y_train_raw, test_size=0.2, random_state=1
    )

    # 3ï¸âƒ£ è®°å½•ç‰¹å¾ç»´åº¦
    input_dim = X_raw.shape[1]

    # 4ï¸âƒ£ æ ‡å‡†åŒ–ï¼ˆä»…å¯¹è®­ç»ƒé›† fitï¼Œå† transform å…¶å®ƒï¼‰
    scaler = StandardScaler().fit(X_train_raw)
    X_train_scaled = scaler.transform(X_train_raw)
    X_val_scaled = scaler.transform(X_val_raw)
    X_test_scaled = scaler.transform(X_test_raw)

    # 5ï¸âƒ£ æ‰©å¢è®­ç»ƒé›†åˆ° 100 ä¸ªæ ·æœ¬
    X_train_aug, y_train_aug = augment_with_noise(X_train_scaled, y_train_raw, target_size=100)

    # âœ… æ‰“å°æ£€æŸ¥ä¿¡æ¯
    print("\nğŸ“¦ æ•°æ®é›†åˆ’åˆ†æ£€æŸ¥ï¼š")
    print(f"åŸå§‹æ ·æœ¬æ€»æ•°ï¼ˆæˆåŠŸ featurize çš„ï¼‰ï¼š{num_total}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°ï¼ˆåŸå§‹æ ·æœ¬ä¸­æŠ½10ä¸ªï¼‰ï¼š{len(X_val_raw)}")
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°ï¼ˆä»è®­ç»ƒé›†ä¸­å†åˆ†å‡º20%ï¼‰ï¼š{len(X_test_raw)}")
    print(f"æœ€ç»ˆç”¨äºæ‰©å¢çš„åŸå§‹è®­ç»ƒæ ·æœ¬æ•°ï¼š{len(X_train_raw)}")
    print(f"æ‰©å¢åè®­ç»ƒæ ·æœ¬æ•°ï¼š{X_train_aug.shape[0]}")
    print(f"è®­ç»ƒé›†ç‰¹å¾ç»´åº¦ï¼š{X_train_aug.shape[1]}")
    print(f"è®­ç»ƒæ ‡ç­¾ shape: {y_train_aug.shape}")
    print(f"éªŒè¯æ ‡ç­¾ shape: {y_val_raw.shape}")
    print(f"æµ‹è¯•æ ‡ç­¾ shape: {y_test_raw.shape}")

    # ğŸ” æ ‡ç­¾åˆ†å¸ƒå›¾
    plt.figure()
    plt.hist(y_train_aug, bins=20, alpha=0.6, label="Train (Augmented)", color='blue')
    plt.hist(y_val_raw, bins=10, alpha=0.6, label="Validation", color='green')
    plt.hist(y_test_raw, bins=10, alpha=0.6, label="Test", color='red')
    plt.title("Target Distribution Across Datasets")
    plt.xlabel("Target Value")
    plt.ylabel("Frequency")
    plt.legend()
    plt.grid(True)
    plt.savefig("prediction_output/target_distribution.png")
    plt.close()

    # ğŸ¯ åˆå§‹åŒ–äº¤å‰éªŒè¯è¯„ä¼°æŒ‡æ ‡å­˜å‚¨
    all_metrics = {'mse': [], 'mae': [], 'r2': [], 'spearman': [], 'pearson': []}

    # ğŸ” äº¤å‰éªŒè¯è®­ç»ƒ
    for fold in range(1, 11):
        print(f"\nğŸš€ å¼€å§‹ç¬¬ {fold}/10 æ¬¡äº¤å‰éªŒè¯")

        train_dataset = MultiSystemDataset(X_train_aug, y_train_aug)
        val_dataset = MultiSystemDataset(X_val_scaled, y_val_raw)
        test_dataset = MultiSystemDataset(X_test_scaled, y_test_raw)

        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)
        val_loader = DataLoader(val_dataset, batch_size=8, num_workers=0)
        test_loader = DataLoader(test_dataset, batch_size=8, num_workers=0)

        model = BatteryModel(input_dim)
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        loss_fn = nn.MSELoss()

        best_val_loss = float('inf')
        train_losses, val_losses = [], []

        for epoch in range(100):
            model.train()
            total_loss = 0
            for X_batch, y_batch in train_loader:
                optimizer.zero_grad()
                pred = model(X_batch)
                loss = loss_fn(pred, y_batch.view(-1, 1))
                if torch.isnan(loss):
                    print("âŒ Loss å‡ºç° NaNï¼Œåœæ­¢è®­ç»ƒ")
                    break
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
            train_losses.append(total_loss / len(train_loader))

            model.eval()
            val_loss = 0
            with torch.no_grad():
                for X_batch, y_batch in val_loader:
                    pred = model(X_batch)
                    val_loss += loss_fn(pred, y_batch.view(-1, 1)).item()
            avg_val_loss = val_loss / len(val_loader)
            val_losses.append(avg_val_loss)
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss

        # ğŸ§  ä¿å­˜æ¨¡å‹
        torch.save(model.state_dict(), f'saved_model/model_fold_{fold}.pt')

        # ğŸ“Š æµ‹è¯•é›†è¯„ä¼°
        model.eval()
        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)
        y_test_tensor = torch.tensor(y_test_raw, dtype=torch.float32).view(-1, 1)
        with torch.no_grad():
            y_pred = model(X_test_tensor).numpy()

        # ğŸ“ˆ å¯è§†åŒ–æŸå¤±
        plt.figure()
        plt.plot(train_losses, label="Training Loss", color='blue')
        plt.plot(val_losses, label="Validation Loss", color='orange')
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.title("Loss Curve")
        plt.legend()
        plt.grid(True)
        plt.savefig(f"training_output/loss_curve_fold_{fold}.png")
        plt.close()

        # ğŸ“Š è¯„ä¼°æŒ‡æ ‡
        y_true = y_test_tensor.numpy()
        mse = mean_squared_error(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        spearman_corr, _ = spearmanr(y_true, y_pred)
        pearson_corr, _ = pearsonr(y_true.flatten(), y_pred.flatten())
        residuals = y_pred.flatten() - y_true.flatten()

        # ğŸ” å„ç±»å›¾è¡¨
        plt.figure()
        plt.plot(y_true, label="True", marker='o')
        plt.plot(y_pred, label="Predicted", marker='x')
        plt.title("Predicted vs True (Test Set)")
        plt.legend()
        plt.grid(True)
        plt.savefig(f"prediction_output/pred_vs_true_fold_{fold}.png")
        plt.close()

        plt.figure()
        plt.scatter(y_true, residuals, label="Residuals")
        plt.axhline(0, color='red', linestyle='--')
        plt.xlabel("True Values")
        plt.ylabel("Residuals")
        plt.title("Residual Plot")
        plt.grid(True)
        plt.savefig(f"prediction_output/residual_fold_{fold}.png")
        plt.close()

        plt.figure()
        plt.hist(residuals, bins=10, edgecolor='black')
        plt.title("Error Histogram")
        plt.savefig(f"prediction_output/error_hist_fold_{fold}.png")
        plt.close()

        all_metrics['mse'].append(mse)
        all_metrics['mae'].append(mae)
        all_metrics['r2'].append(r2)
        all_metrics['spearman'].append(spearman_corr)
        all_metrics['pearson'].append(pearson_corr)

        print(
            f"âœ… Fold {fold}: MSE={mse:.4f}, MAE={mae:.4f}, RÂ²={r2:.4f}, Spearman={spearman_corr:.4f}, Pearson={pearson_corr:.4f}")

    # ğŸ§¾ æ±‡æ€»ç»“æœ
    print("\nğŸ“Š äº¤å‰éªŒè¯ç»“æœç»Ÿè®¡ï¼š")
    with open("prediction_output/crossval_metrics_summary.txt", "w") as f:
        for metric_name, values in all_metrics.items():
            mean_val = np.mean(values)
            std_val = np.std(values)
            result = f"{metric_name.upper()}: Mean={mean_val:.4f}, Std={std_val:.4f}"
            print(result)
            f.write(result + "\n")

    # ğŸ“¦ RÂ² åˆ†å¸ƒå›¾
    plt.figure()
    plt.boxplot(all_metrics['r2'], patch_artist=True, labels=['RÂ²'])
    plt.title('RÂ² Score Distribution')
    plt.grid(True)
    plt.savefig("prediction_output/r2_score_boxplot.png")
    plt.close()

    print("\nâœ… å…¨éƒ¨å®Œæˆï¼Œäº¤å‰éªŒè¯å›¾è¡¨å’Œè¯„ä¼°æŒ‡æ ‡å·²ä¿å­˜ï¼")
